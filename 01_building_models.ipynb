{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_building_models.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Parameters\n",
        "As each layer has to have parameters to optimize, we can take advantage of inheriting from ``torch.nn.module`` which will automatically initialize parameters and let us access them through ``.parameters``. \n",
        "\n",
        "We can also call it like ``ourModel.layer1.parameters`` to get parameters from each layer."
      ],
      "metadata": {
        "id": "H2w9Xdc8KhG-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W-L6Y2RoZW2",
        "outputId": "52f8960f-3acc-4559-e769-f81164dce6a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model:\n",
            "TinyModel(\n",
            "  (linear1): Linear(in_features=100, out_features=200, bias=True)\n",
            "  (activation): ReLU()\n",
            "  (linear2): Linear(in_features=200, out_features=10, bias=True)\n",
            "  (softmax): Softmax(dim=None)\n",
            ")\n",
            "\n",
            "\n",
            "Just one layer:\n",
            "Linear(in_features=200, out_features=10, bias=True)\n",
            "\n",
            "\n",
            "Model params:\n",
            "Parameter containing:\n",
            "tensor([[ 0.0712, -0.0377,  0.0109,  ..., -0.0785,  0.0111, -0.0461],\n",
            "        [-0.0718,  0.0098, -0.0558,  ..., -0.0135,  0.0270,  0.0469],\n",
            "        [ 0.0771,  0.0760, -0.0102,  ..., -0.0148,  0.0981,  0.0519],\n",
            "        ...,\n",
            "        [-0.0368,  0.0069, -0.0224,  ..., -0.0319, -0.0021, -0.0945],\n",
            "        [ 0.0460,  0.0065, -0.0102,  ...,  0.0793,  0.0473, -0.0010],\n",
            "        [-0.0654, -0.0202, -0.0502,  ...,  0.0312,  0.0371,  0.0165]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-7.1293e-02, -8.8269e-02, -9.7207e-02, -2.8489e-02,  7.6750e-02,\n",
            "         1.4393e-03,  8.7211e-02, -1.3204e-02,  5.6359e-02, -7.1892e-02,\n",
            "        -6.4634e-02, -8.3759e-02,  6.7112e-02, -3.5226e-02, -9.2744e-03,\n",
            "         5.8448e-02, -2.3300e-02, -9.0531e-02, -3.8266e-06,  2.8368e-02,\n",
            "         5.1913e-02, -5.4235e-02,  4.0831e-02, -8.1899e-03, -2.3138e-02,\n",
            "         1.4669e-02,  5.8087e-02, -7.7605e-02, -5.7927e-02, -2.1158e-03,\n",
            "         6.2284e-02,  2.2363e-02,  8.6955e-02,  4.0724e-02, -1.7622e-02,\n",
            "         5.2649e-02,  4.4993e-02,  3.7402e-02, -2.5688e-02, -3.7639e-03,\n",
            "        -7.6072e-02, -7.4084e-02, -7.3671e-02, -9.9480e-02,  3.6689e-02,\n",
            "        -9.6484e-02,  5.2470e-02, -1.1652e-02,  2.7425e-02, -1.6001e-02,\n",
            "        -3.6470e-02, -8.4348e-02, -8.3322e-02,  1.6961e-02,  4.2805e-02,\n",
            "         5.5156e-02,  6.7367e-03, -6.4758e-03, -6.9499e-02, -9.2330e-02,\n",
            "        -9.6398e-02, -5.8941e-02, -2.7103e-03,  3.6029e-02,  9.8905e-02,\n",
            "         3.4223e-02, -4.4047e-02,  4.6164e-02,  2.7334e-02,  6.3687e-02,\n",
            "        -3.5861e-02,  9.3478e-02,  8.1814e-02,  9.0025e-02,  1.8097e-04,\n",
            "        -2.0314e-02,  7.9390e-02, -5.6492e-02,  1.5254e-02,  3.9649e-02,\n",
            "         1.6487e-04, -2.3676e-02,  6.9297e-02,  3.2901e-02, -9.6439e-02,\n",
            "         2.8250e-02, -4.5844e-02, -6.8351e-02, -6.9627e-02,  8.2320e-02,\n",
            "        -2.9618e-02,  7.3442e-02, -5.0150e-02,  3.8963e-02, -1.9917e-02,\n",
            "         1.1895e-02,  2.0415e-02, -7.1383e-02,  9.0878e-02,  3.6754e-02,\n",
            "        -7.6888e-02, -5.7954e-03, -8.0813e-02,  7.0594e-02, -2.7887e-02,\n",
            "         3.4179e-02, -9.1974e-02,  4.9645e-02, -8.7808e-02,  7.7004e-04,\n",
            "        -2.3432e-02,  9.7537e-02,  8.1410e-02,  9.4504e-03,  3.0568e-02,\n",
            "         7.1560e-02,  7.3988e-02, -2.2935e-02,  2.7883e-03, -2.6834e-03,\n",
            "        -4.9838e-02, -3.8793e-02,  8.0061e-02, -9.2934e-02,  6.7899e-03,\n",
            "        -3.4111e-02,  8.1705e-02,  8.5604e-02,  2.1585e-03,  8.6748e-02,\n",
            "        -1.0891e-02,  4.3882e-02, -5.4149e-02, -9.9690e-02,  6.4123e-02,\n",
            "        -9.7913e-02, -3.8640e-02,  2.3421e-03,  6.8177e-02, -6.6985e-02,\n",
            "         1.1574e-02,  9.1626e-02, -6.7202e-02, -2.6021e-02, -9.2926e-02,\n",
            "         6.0600e-02,  4.1828e-02,  6.4337e-02,  5.9053e-02, -3.1172e-03,\n",
            "         4.8103e-02, -7.0522e-02, -1.9803e-04, -8.3692e-02,  2.7329e-02,\n",
            "        -4.1013e-02, -8.8223e-02,  7.1095e-02, -5.8808e-02,  8.4699e-02,\n",
            "         1.5919e-02,  5.7717e-02, -1.6042e-03,  1.6319e-02,  8.1497e-02,\n",
            "        -7.6075e-02,  1.8787e-03, -8.7256e-02,  9.0025e-02,  5.0133e-02,\n",
            "        -5.2827e-02, -1.3480e-02, -3.9927e-02,  6.8833e-02,  6.3294e-03,\n",
            "        -7.0058e-02, -1.8019e-02, -2.9493e-02,  2.6291e-02,  8.6749e-02,\n",
            "         8.0895e-02, -9.4796e-02,  9.9567e-02,  3.1630e-02,  5.4544e-02,\n",
            "        -6.9858e-02, -1.9251e-02,  6.6028e-02, -1.5118e-02,  8.4382e-02,\n",
            "         5.3137e-03, -4.2645e-02,  1.4424e-02,  3.2135e-03, -3.2782e-02,\n",
            "         4.4817e-02,  6.5765e-02, -7.6643e-02, -8.6457e-02,  9.4638e-02],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0387,  0.0205,  0.0549,  ...,  0.0084, -0.0605,  0.0645],\n",
            "        [-0.0365,  0.0010,  0.0228,  ...,  0.0347,  0.0146, -0.0527],\n",
            "        [-0.0104,  0.0646, -0.0060,  ...,  0.0402, -0.0527, -0.0422],\n",
            "        ...,\n",
            "        [-0.0141,  0.0228, -0.0028,  ...,  0.0190, -0.0186,  0.0255],\n",
            "        [-0.0162,  0.0378, -0.0071,  ...,  0.0054,  0.0024, -0.0306],\n",
            "        [-0.0417, -0.0608,  0.0435,  ..., -0.0517,  0.0468,  0.0020]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0105,  0.0262, -0.0551, -0.0392, -0.0579,  0.0502, -0.0438,  0.0190,\n",
            "         0.0458,  0.0610], requires_grad=True)\n",
            "\n",
            "\n",
            "Layer params:\n",
            "Parameter containing:\n",
            "tensor([[-0.0387,  0.0205,  0.0549,  ...,  0.0084, -0.0605,  0.0645],\n",
            "        [-0.0365,  0.0010,  0.0228,  ...,  0.0347,  0.0146, -0.0527],\n",
            "        [-0.0104,  0.0646, -0.0060,  ...,  0.0402, -0.0527, -0.0422],\n",
            "        ...,\n",
            "        [-0.0141,  0.0228, -0.0028,  ...,  0.0190, -0.0186,  0.0255],\n",
            "        [-0.0162,  0.0378, -0.0071,  ...,  0.0054,  0.0024, -0.0306],\n",
            "        [-0.0417, -0.0608,  0.0435,  ..., -0.0517,  0.0468,  0.0020]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0105,  0.0262, -0.0551, -0.0392, -0.0579,  0.0502, -0.0438,  0.0190,\n",
            "         0.0458,  0.0610], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "class TinyModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.linear1 = torch.nn.Linear(100, 200)\n",
        "        self.activation = torch.nn.ReLU()\n",
        "        self.linear2 = torch.nn.Linear(200, 10)\n",
        "        self.softmax = torch.nn.Softmax()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.linear2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "tinymodel = TinyModel()\n",
        "\n",
        "print('The model:')\n",
        "print(tinymodel)\n",
        "\n",
        "print('\\n\\nJust one layer:')\n",
        "print(tinymodel.linear2)\n",
        "\n",
        "print('\\n\\nModel params:')\n",
        "for param in tinymodel.parameters():\n",
        "    print(param)\n",
        "\n",
        "print('\\n\\nLayer params:')\n",
        "for param in tinymodel.linear2.parameters():\n",
        "    print(param)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear Layers (fully connected layers)\n",
        "Every input influences every output by some degree. The weight matrix will be *m* × *n*, where *m* - input length, *n* - output length. Operation is: *x* × *w* + *b*, where *w* - weights, *b* - biases. Mostly used as classifing layers."
      ],
      "metadata": {
        "id": "vLBR0IvgNXmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lin = torch.nn.Linear(3, 2)\n",
        "x = torch.rand(1, 3)\n",
        "print('Input:')\n",
        "print(x)\n",
        "\n",
        "print('\\n\\nWeight and Bias parameters:')\n",
        "for enum, param in enumerate(lin.parameters(), 1):\n",
        "    print(f\"{enum}.\", param)\n",
        "\n",
        "y = lin(x)\n",
        "print('\\n\\nOutput:')\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eof5eq2QKDQN",
        "outputId": "2c63651e-9af8-4ca3-ac9d-49cd6c138b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            "tensor([[0.9432, 0.2330, 0.9948]])\n",
            "\n",
            "\n",
            "Weight and Bias parameters:\n",
            "1. Parameter containing:\n",
            "tensor([[0.2523, 0.1990, 0.0547],\n",
            "        [0.1292, 0.5412, 0.2115]], requires_grad=True)\n",
            "2. Parameter containing:\n",
            "tensor([ 0.3272, -0.4525], requires_grad=True)\n",
            "\n",
            "\n",
            "Output:\n",
            "tensor([[0.6659, 0.0059]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional Layers\n",
        "\n",
        "Handle high degree of spatial correlation. Mostly used in vision and NLP where they detect close grouping of features and compose them into higher-level features. Convolutional filter (cross-correlation, but who cares), slides across input, multiplies (dot product) with input that it slides over, sums the result and puts it into it's central element position on output matrix. \n",
        "\n",
        "Input:\n",
        "\\begin{array}{|c|c|} \\hline\n",
        "0 & 1 & 1 & 0\\\\ \\hline\n",
        "0 & 1 & -1 & 0\\\\ \\hline\n",
        "0 & 1 & 1 & 0\\\\ \\hline\n",
        "0 & 1 & -1 & 0\\\\ \\hline\n",
        "\\end{array}\n",
        "\n",
        "Filter:\n",
        "\\begin{array}{|c|c|} \\hline\n",
        "0 & 1 & 0  \\\\ \\hline\n",
        "0 & 1 & 0  \\\\\\hline\n",
        "0 & 1 & 0  \\\\ \\hline\n",
        "\\end{array}\n",
        "\n",
        "Convolution result:\n",
        "\\begin{array}{|c|c|} \\hline\n",
        "3 & 2  \\\\ \\hline\n",
        "3 & 1  \\\\ \\hline\n",
        "\\end{array}"
      ],
      "metadata": {
        "id": "vSKMkGQRP_G7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.functional as F\n",
        "\n",
        "\n",
        "class LeNet(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 1 input image channel (black & white), 6 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = torch.nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = torch.nn.Conv2d(6, 16, 3)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = torch.nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension\n",
        "        self.fc2 = torch.nn.Linear(120, 84)\n",
        "        self.fc3 = torch.nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features"
      ],
      "metadata": {
        "id": "jx1zAVOEOLu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at max pool"
      ],
      "metadata": {
        "id": "Peot-na9kcNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "test_tensor = np.floor(torch.randn(3, 3) * 10)\n",
        "test_tensor = test_tensor.reshape(1, 1, 3, 3) \n",
        "print(f\"Test tensor ({test_tensor.shape}): \\n {test_tensor}\")\n",
        "\n",
        "test_tensor = F.max_pool2d(input=test_tensor, kernel_size=2, stride=1)\n",
        "print(f\"\\n Maxpool2d(kernel=2, stride=1) tensor: \\n {test_tensor}\")\n",
        "\n",
        "test_tensor = F.max_pool2d(input=test_tensor, kernel_size=2, stride=2)\n",
        "print(f\"\\n Maxpool2d(kernel=2, stride=2) tensor: \\n {test_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BE85Dpp6QavS",
        "outputId": "1472f761-6cd5-456a-e1ce-85ac7d1524c5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test tensor (torch.Size([1, 1, 3, 3])): \n",
            " tensor([[[[-11.,   9.,   9.],\n",
            "          [ 12.,  -6., -12.],\n",
            "          [  5.,   1., -27.]]]])\n",
            "\n",
            " Maxpool2d(kernel=2, stride=1) tensor: \n",
            " tensor([[[[12.,  9.],\n",
            "          [12.,  1.]]]])\n",
            "\n",
            " Maxpool2d(kernel=2, stride=2) tensor: \n",
            " tensor([[[[12.]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recurrent Layers\n",
        "Mostly used for sequential data: time-series, NLP, DNA etc. Recurrent Neural Networks maintains a hidden state that acts as \"memory\" for previous sequence elements. We can also distinct LSTM (long short-term memory) and GRU (gated recurrent unit).\n",
        "\n",
        "``vocab_size`` - number of words in the input vocabulary. Each word is a unit vector (one-hot vector) spanning *vocab_size*-dimensional space.\n",
        "\n",
        "``tagset_size`` - number of tags in the output set.\n",
        "\n",
        "``embedding_dim`` - size of embedding space for the vocabulary. An embedding maps a vocabulary onto a low-dimensional space, where words with similar meanings are close together in space.\n",
        "\n",
        "``hidden_dim`` - size of the LSTM memory.\n",
        "\n",
        "Input is a sentence represented as indices of unit vectors. Embedding maps these vectors to *embedding_dim*-dimensional space. Then LSTM takes this sequence and iterates over, fielding(?populating?) an output vector of length *hidden_dim*. Final layer acts as classifier, it applies a log softmax function to the output which converts the output into a normalized set of estimated probabilites that a given word maps to given tag. "
      ],
      "metadata": {
        "id": "Voxv2mpik1Ze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMTagger(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.word_embeddings = torch.nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
        "        # with dimensionality hidden_dim.\n",
        "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim)\n",
        "\n",
        "        # The linear layer that maps from hidden state space to tag space\n",
        "        self.hidden2tag = torch.nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ],
      "metadata": {
        "id": "nGkc61JxgYlZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformers\n",
        "A story for another time."
      ],
      "metadata": {
        "id": "c9svmbOsreaU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalization\n",
        "Standard normalization almost:\n",
        "\n",
        "$y = \\frac{x - \\overline{x}}{\\sqrt{Var(x) + ϵ}} ⋅ \\gamma + β$\n",
        "\n",
        "Stochastic element + learnable weights and biases. Helps to omit vanishing and exploding gradients."
      ],
      "metadata": {
        "id": "4upcPlx6rwCJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = torch.rand(1, 4, 4) * 20 + 5\n",
        "print(my_tensor)\n",
        "\n",
        "print(my_tensor.mean())\n",
        "\n",
        "norm_layer = torch.nn.BatchNorm1d(4)\n",
        "normed_tensor = norm_layer(my_tensor)\n",
        "print(normed_tensor)\n",
        "\n",
        "print(normed_tensor.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8o4zVJrGrust",
        "outputId": "e67cb2bb-7f08-4269-eae7-b05c3fe74bea"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 7.7846, 20.0338, 14.1320, 13.6748],\n",
            "         [10.7732, 20.7029, 24.6519, 18.2458],\n",
            "         [ 7.2304, 10.5616,  9.6020, 22.0810],\n",
            "         [14.8418,  9.8019, 10.2987, 23.6716]]])\n",
            "tensor(14.8805)\n",
            "tensor([[[-1.4126,  1.4139,  0.0521, -0.0534],\n",
            "         [-1.5454,  0.4169,  1.1972, -0.0687],\n",
            "         [-0.8957, -0.3150, -0.4823,  1.6929],\n",
            "         [ 0.0338, -0.8719, -0.7826,  1.6206]]],\n",
            "       grad_fn=<NativeBatchNormBackward0>)\n",
            "tensor(5.2154e-08, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dropout Layers\n",
        "Hide random part of input for training in order to encourage the model to introduce sparse representation. "
      ],
      "metadata": {
        "id": "7zjUV2UCuwqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_tensor = torch.rand(1, 4, 4)\n",
        "\n",
        "dropout = torch.nn.Dropout(p=0.4)\n",
        "print(dropout(my_tensor))\n",
        "print(dropout(my_tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9DVUtgatbqH",
        "outputId": "02b09ef0-7b87-49a1-d840-f5c3dbce2b08"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.0000, 0.2525, 1.4495, 0.1898],\n",
            "         [0.7042, 0.0426, 0.1532, 0.1669],\n",
            "         [0.0000, 0.3141, 1.2422, 0.8919],\n",
            "         [1.3825, 1.6480, 0.2737, 1.0767]]])\n",
            "tensor([[[0.8361, 0.2525, 1.4495, 0.0000],\n",
            "         [0.0000, 0.0426, 0.0000, 0.1669],\n",
            "         [1.1787, 0.0000, 1.2422, 0.8919],\n",
            "         [1.3825, 1.6480, 0.0000, 1.0767]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activation functions\n",
        "Introduce non-linear functions into deep learning models. "
      ],
      "metadata": {
        "id": "oaHAnl2gvP9C"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lVKujGY5vO6Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}